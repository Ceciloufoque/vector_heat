{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import potpourri3d as pp3d\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.spatial import KDTree\n",
    "import gdist\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def unify_vertices(source_file_path, tolerance=1e-5):\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    \n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces\n",
    "\n",
    "    # Step 1: Find unique vertices within the given tolerance\n",
    "    kdtree = KDTree(vertices)\n",
    "    unique_indices = {}\n",
    "    canonical_vertices = []\n",
    "    \n",
    "    for i, vertex in enumerate(vertices):\n",
    "        if i in unique_indices:\n",
    "            continue  # Skip if already mapped to a canonical vertex\n",
    "        \n",
    "        # Find all vertices within the tolerance distance\n",
    "        duplicate_indices = kdtree.query_ball_point(vertex, tolerance)\n",
    "        \n",
    "        # Use the first duplicate as the \"canonical\" vertex and map all duplicates to it\n",
    "        canonical_index = len(canonical_vertices)\n",
    "        canonical_vertices.append(vertex)\n",
    "        \n",
    "        for idx in duplicate_indices:\n",
    "            unique_indices[idx] = canonical_index\n",
    "\n",
    "    # Step 2: Update faces to use only unique vertices\n",
    "    new_faces = np.array([[unique_indices[vi] for vi in face] for face in faces])\n",
    "\n",
    "    # Step 3: Create the new unified mesh\n",
    "    unified_mesh = trimesh.Trimesh(vertices=np.array(canonical_vertices), faces=new_faces)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_fixed.obj'\n",
    "    unified_mesh.export(output_path)\n",
    "    print(f'Mesh unified and saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicate_edges(source_file_path):\n",
    "        mesh = trimesh.load(source_file_path)\n",
    "\n",
    "    edges = mesh.edges\n",
    "    faces = mesh.faces\n",
    "    sorted_edges = np.sort(edges, axis=1)\n",
    "\n",
    "    # Find unique edges\n",
    "    _, unique_indices = np.unique(sorted_edges, axis=0, return_index=True)\n",
    "    unique_edges = edges[unique_indices]\n",
    "\n",
    "    # Find the vertices used by unique edges\n",
    "    unique_vertices = np.unique(unique_edges)\n",
    "\n",
    "    # Remap vertices for the unique edges\n",
    "    vertex_map = {old_index: new_index for new_index, old_index in enumerate(unique_vertices)}\n",
    "    remapped_vertices = np.array([vertex_map[vertex] for vertex in unique_vertices])\n",
    "\n",
    "    # Recreate the mesh using the unique edges and remapped vertices\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices[remapped_vertices], faces=faces, process=False)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_edges_cleaned.obj'\n",
    "    new_mesh.export(output_path)\n",
    "    print(f'Mesh cleaned and saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_faces_by_indices(mesh, face_indices):\n",
    "    # Convert face_indices to a set for fast exclusion\n",
    "    face_indices_set = set(face_indices)\n",
    "\n",
    "    # Create a mask that selects all faces except those we want to remove\n",
    "    mask = [i not in face_indices_set for i in range(len(mesh.faces))]\n",
    "\n",
    "    # Filter the faces array\n",
    "    new_faces = mesh.faces[mask]\n",
    "\n",
    "    # Recreate the mesh with the remaining faces\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices, faces=new_faces, process=False)\n",
    "    \n",
    "    return new_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nmwsharp/robust-laplacians-py/issues/1\n",
    "def add_random_jitter(mesh, level=1e-5, write_file=False):\n",
    "    mean_edge_length = mesh.edges_unique_length.mean()\n",
    "    jittered_vertices = mesh.vertices + np.random.normal(0, mean_edge_length*level, size=mesh.vertices.shape)\n",
    "    mesh = trimesh.Trimesh(vertices=jittered_vertices, faces= mesh.faces)\n",
    "    if write_file is not None:\n",
    "        output_path = f'{write_file[:-4]}_random_faces_{level*100:d}.obj'\n",
    "        mesh.export(output_path)\n",
    "        print(f'Mesh jittered and saved to {output_path}')\n",
    "    return mesh\n",
    "\n",
    "def preprocess_edges_to_faces(faces):\n",
    "    edge_to_faces = defaultdict(list)\n",
    "    for face_idx, face in enumerate(faces):\n",
    "        # For each face, add its edges to the map\n",
    "        edges = [(face[i], face[(i + 1) % 3]) for i in range(3)]  # Get edges of the triangle\n",
    "        for edge in edges:\n",
    "            sorted_edge = tuple(sorted(edge))  # Sort edge to ensure consistent representation\n",
    "            edge_to_faces[sorted_edge].append(face_idx)\n",
    "    return edge_to_faces\n",
    "\n",
    "def modify_mesh_faces(mesh, level=0.1, write_file=None):\n",
    "    faces = mesh.faces\n",
    "    vertices = mesh.vertices\n",
    "    num_faces_to_modify = int(len(faces) * level)\n",
    "    modified_faces = faces[:]\n",
    "    edge_to_faces = preprocess_edges_to_faces(faces)\n",
    "    modified_indices = set()\n",
    "    for _ in tqdm(range(num_faces_to_modify)):\n",
    "        face_idx = np.random.choice([i for i in range(len(modified_faces)) if i not in modified_indices])\n",
    "        face = modified_faces[face_idx]\n",
    "        v1, v2 = np.random.choice(face, 2)\n",
    "        sorted_edge = tuple(sorted((v1, v2)))\n",
    "        neighbor_face_indices = edge_to_faces[sorted_edge]\n",
    "        neighbor_face_idx = next((idx for idx in neighbor_face_indices if idx != face_idx and idx not in modified_indices), None)\n",
    "        \n",
    "        if neighbor_face_idx is not None:\n",
    "            neighbor_face = modified_faces[neighbor_face_idx]\n",
    "            v3 = next(v for v in face if v not in (v1, v2))\n",
    "            v4 = next(v for v in neighbor_face if v not in (v1, v2))\n",
    "            modified_faces[face_idx] = [v1, v3, v4]\n",
    "            modified_faces[neighbor_face_idx] = [v2, v3, v4]\n",
    "            modified_indices.add(face_idx)\n",
    "            modified_indices.add(neighbor_face_idx)\n",
    "\n",
    "    mesh = trimesh.Trimesh(vertices=vertices, faces= modified_faces)\n",
    "    if write_file is not None:\n",
    "        output_path = f'{write_file[:-4]}_random_faces_{int(level*100)}.obj'\n",
    "        mesh.export(output_path)\n",
    "        print(f'Randomized mesh faces and saved to {output_path}')\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mesh(mesh, distances =None, sources= None, intrinsic_vectors=None):\n",
    "    plotter = pv.Plotter()\n",
    "    normalized_distances = None\n",
    "    if distances is not None:\n",
    "        normalized_distances = (distances - distances.min()) / (distances.max() - distances.min())\n",
    "        plotter.add_points(mesh.vertices[sources].reshape(sources.shape[0], 3), color=\"red\", render_points_as_spheres=True, point_size=10)\n",
    "    faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "    pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "    colors = np.tile([\"white\", \"blue\"], 10)\n",
    "    cmap = ListedColormap(colors)\n",
    "    plotter.add_mesh(pv_mesh, scalars=normalized_distances, cmap=cmap, show_edges=False)\n",
    "    \n",
    "    if intrinsic_vectors is not None:\n",
    "        vector_solver = pp3d.MeshVectorHeatSolver(mesh.vertices, mesh.faces)\n",
    "        basisX, basisY, basisN = vector_solver.get_tangent_frames()\n",
    "        ext3D = intrinsic[:,0,np.newaxis] * basisX +  intrinsic[:,1,np.newaxis] * basisY\n",
    "        mean_edge_length = mesh.edges_unique_length.mean()\n",
    "        plotter.add_arrows(mesh.vertices, ext3D, mag=mean_edge_length)\n",
    "    plotter.show(title=\"Geodesic Distance Visualization\")\n",
    "    plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized mesh faces and saved to cow_random_faces_0.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized mesh faces and saved to stanford-bunny_random_faces_0.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized mesh faces and saved to horse_random_faces_0.obj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmesh = trimesh.load('cow_random_faces_30.obj')\\nsources = np.array([750])\\ndistances = get_scalar_heat_geodesic(mesh, sources)\\nshow_mesh(mesh, distances=distances, sources=sources)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mesh = add_random_jitter(mesh, level=0)\n",
    "\n",
    "for mesh_name in ['cow.obj', 'stanford-bunny.obj', 'horse.obj']:\n",
    "    mesh = trimesh.load(mesh_name)\n",
    "    for noise in [0.0]:\n",
    "        modify_mesh_faces(mesh, noise, mesh_name)\n",
    "\n",
    "\n",
    "'''\n",
    "mesh = trimesh.load('cow_random_faces_30.obj')\n",
    "sources = np.array([750])\n",
    "distances = get_scalar_heat_geodesic(mesh, sources)\n",
    "show_mesh(mesh, distances=distances, sources=sources)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalar_heat_geodesic(mesh, vertex_indices):\n",
    "    heat_solver = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "    return heat_solver.compute_distance_multisource(vertex_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_geodesic(mesh, vertex_indices):\n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces  # Mesh faces\n",
    "    geodesic_distances = gdist.compute_gdist(\n",
    "        vertices.astype(np.float64),\n",
    "        faces.astype(np.int32),\n",
    "        vertex_indices\n",
    "    )\n",
    "    return geodesic_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proximity(distances_exact, distances_approx, epsilon = 0.01):\n",
    "    distances_exact = (distances_exact - distances_exact.min()) / (distances_exact.max() - distances_exact.min())\n",
    "    distances_approx = (distances_approx - distances_approx.min()) / (distances_approx.max() - distances_approx.min())\n",
    "    return np.count_nonzero(np.abs(distances_exact-distances_approx) < epsilon)/distances_exact.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_exact_geodesic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m mesh \u001b[38;5;241m=\u001b[39m trimesh\u001b[38;5;241m.\u001b[39mload(mesh_name)\n\u001b[0;32m     15\u001b[0m source_vertices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, mesh\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m exact_mesh_distances \u001b[38;5;241m=\u001b[39m \u001b[43mget_exact_geodesic\u001b[49m(mesh, source_vertices)\n\u001b[0;32m     17\u001b[0m jittered_mesh \u001b[38;5;241m=\u001b[39m add_random_jitter(mesh, level\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[0;32m     18\u001b[0m exact_jittered_distances \u001b[38;5;241m=\u001b[39m get_exact_geodesic(jittered_mesh, source_vertices)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_exact_geodesic' is not defined"
     ]
    }
   ],
   "source": [
    "source_vertices = np.array([0])\n",
    "precision_percentage = 2\n",
    "noise_levels = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "meshes = ['cow.obj']#, 'stanford-bunny.obj', 'horse.obj']\n",
    "\n",
    "original_vs_noisy_proximities = []\n",
    "noisy_vs_noisy_proximities = []\n",
    "for mesh_name in meshes:\n",
    "    samples = 10\n",
    "    original_vs_noisy_proximities_current_mesh = np.zeros([samples, len(noise_levels)])\n",
    "    noisy_vs_noisy_proximities_current_mesh = np.zeros([samples, len(noise_levels)])\n",
    "    for i, noise in enumerate(noise_levels):\n",
    "        for j in range(samples):\n",
    "            mesh = trimesh.load(mesh_name)\n",
    "            source_vertices = np.random.randint(0, mesh.vertices.shape[0], 1)\n",
    "            exact_mesh_distances = get_exact_geodesic(mesh, source_vertices)\n",
    "            jittered_mesh = add_random_jitter(mesh, level=noise)\n",
    "            exact_jittered_distances = get_exact_geodesic(jittered_mesh, source_vertices)\n",
    "            shm_jittered_distances = get_scalar_heat_geodesic(jittered_mesh, source_vertices)\n",
    "            original_vs_noisy_proximities_current_mesh[j, i] = get_proximity(exact_mesh_distances, shm_jittered_distances, precision_percentage/100)\n",
    "            noisy_vs_noisy_proximities_current_mesh[j, i] = get_proximity(exact_jittered_distances, shm_jittered_distances, precision_percentage/100)\n",
    "    original_vs_noisy_proximities.append(original_vs_noisy_proximities_current_mesh)\n",
    "    noisy_vs_noisy_proximities.append(noisy_vs_noisy_proximities_current_mesh)\n",
    "\n",
    "plt.title('Distance accuracy exact original vs SHM gaussian noise')\n",
    "plt.xlabel('Noise variance as a % of average edge length')\n",
    "plt.ylabel(f'% vertex distances off by <{precision_percentage}%')\n",
    "for i, mesh_name in enumerate(meshes):\n",
    "    y = original_vs_noisy_proximities[i]\n",
    "    y_mean = np.percentile(y, 50, axis=0)\n",
    "    y_lower = np.percentile(y, 25, axis=0)\n",
    "    y_upper = np.percentile(y, 75, axis=0)\n",
    "    error_lower = y_mean - y_lower\n",
    "    error_upper = y_upper - y_mean\n",
    "    plt.errorbar(noise_levels, y_mean, yerr=[error_lower, error_upper], linewidth=2, label=mesh_name)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Distance accuracy exact vs SHM for gaussian noise')\n",
    "plt.xlabel('Noise variance as a % of average edge length')\n",
    "plt.ylabel(f'% vertex <{precision_percentage}% from exact value')\n",
    "for i, mesh_name in enumerate(meshes):\n",
    "    y = noisy_vs_noisy_proximities[i]\n",
    "    y_mean = np.percentile(y, 50, axis=0)\n",
    "    y_lower = np.percentile(y, 25, axis=0)\n",
    "    y_upper = np.percentile(y, 75, axis=0)\n",
    "    error_lower = y_mean - y_lower\n",
    "    error_upper = y_upper - y_mean\n",
    "    plt.errorbar(noise_levels, y_mean, yerr=[error_lower, error_upper], linewidth=2, label=mesh_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh: cow_random_faces_0.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh: cow_random_faces_1.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "string is not a file: cow_random_faces_1.obj",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_random_faces_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(noise\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.obj\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMesh: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m swapped_triangles_mesh \u001b[38;5;241m=\u001b[39m  \u001b[43mtrimesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(samples):\n\u001b[0;32m     17\u001b[0m     source_vertices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, swapped_triangles_mesh\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\icel_\\miniconda3\\lib\\site-packages\\trimesh\\exchange\\load.py:114\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file_obj, file_type, resolver, force, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_obj\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# parse the file arguments into clean loadable form\u001b[39;00m\n\u001b[0;32m    108\u001b[0m (\n\u001b[0;32m    109\u001b[0m     file_obj,  \u001b[38;5;66;03m# file- like object\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     file_type,  \u001b[38;5;66;03m# str, what kind of file\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     metadata,  \u001b[38;5;66;03m# dict, any metadata from file name\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     opened,  \u001b[38;5;66;03m# bool, did we open the file ourselves\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     resolver,  \u001b[38;5;66;03m# object to load referenced resources\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_file_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;66;03m# if we've been passed a dict treat it as kwargs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\icel_\\miniconda3\\lib\\site-packages\\trimesh\\exchange\\load.py:612\u001b[0m, in \u001b[0;36m_parse_file_args\u001b[1;34m(file_obj, file_type, resolver, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse load_remote to load URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m file_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring is not a file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    615\u001b[0m     file_type \u001b[38;5;241m=\u001b[39m file_obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: string is not a file: cow_random_faces_1.obj"
     ]
    }
   ],
   "source": [
    "source_vertices = np.array([0])\n",
    "precision_percentage = 2\n",
    "noise_levels = [0, 0.1, 0.2, 0.3]\n",
    "meshes = ['cow', 'stanford-bunny', 'horse']\n",
    "\n",
    "original_vs_swapped_noisy_proximities = []\n",
    "noisy_vs_swapped_noisy_proximities = []\n",
    "for mesh_name in meshes:\n",
    "    samples = 10\n",
    "    original_vs_noisy_proximities_current_mesh = np.zeros([samples, len(noise_levels)])\n",
    "    noisy_vs_noisy_proximities_current_mesh = np.zeros([samples, len(noise_levels)])\n",
    "    for i, noise in tqdm(enumerate(noise_levels)):\n",
    "        path = f'{mesh_name}_random_faces_{int(noise*100)}.obj'\n",
    "        print(f'Mesh: {path}')\n",
    "        swapped_triangles_mesh =  trimesh.load(path)\n",
    "        for j in range(samples):\n",
    "            source_vertices = np.random.randint(0, swapped_triangles_mesh.vertices.shape[0], 1)\n",
    "            exact_mesh_distances = get_exact_geodesic(swapped_triangles_mesh, source_vertices)\n",
    "            exact_swapped_distances = get_exact_geodesic(swapped_triangles_mesh, source_vertices)\n",
    "            shm_swapped_distances = get_scalar_heat_geodesic(swapped_triangles_mesh, source_vertices)\n",
    "            original_vs_noisy_proximities_current_mesh[j, i] = get_proximity(exact_mesh_distances, shm_swapped_distances, precision_percentage/100)\n",
    "            noisy_vs_noisy_proximities_current_mesh[j, i] = get_proximity(exact_swapped_distances, shm_swapped_distances, precision_percentage/100)\n",
    "    original_vs_swapped_noisy_proximities.append(original_vs_noisy_proximities_current_mesh)\n",
    "    noisy_vs_swapped_noisy_proximities.append(noisy_vs_noisy_proximities_current_mesh)\n",
    "\n",
    "plt.title('Distance accuracy exact original vs SHM traingle swapping noise')\n",
    "plt.xlabel('Noise as a % of swapped faces')\n",
    "plt.ylabel(f'% vertex distances off by <{precision_percentage}%')\n",
    "for i, mesh_name in enumerate(meshes):\n",
    "    y = original_vs_swapped_noisy_proximities[i]\n",
    "    y_mean = np.percentile(y, 50, axis=0)\n",
    "    y_lower = np.percentile(y, 25, axis=0)\n",
    "    y_upper = np.percentile(y, 75, axis=0)\n",
    "    error_lower = y_mean - y_lower\n",
    "    error_upper = y_upper - y_mean\n",
    "    plt.errorbar(noise_levels, y_mean, yerr=[error_lower, error_upper], linewidth=2, label=mesh_name)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Distance accuracy exact vs SHM for traingle swapping noise')\n",
    "plt.xlabel('Noise as a % of swapped faces')\n",
    "plt.ylabel(f'% vertex distances off by <{precision_percentage}%')\n",
    "for i, mesh_name in enumerate(meshes):\n",
    "    y = noisy_vs_swapped_noisy_proximities[i]\n",
    "    y_mean = np.percentile(y, 50, axis=0)\n",
    "    y_lower = np.percentile(y, 25, axis=0)\n",
    "    y_upper = np.percentile(y, 75, axis=0)\n",
    "    error_lower = y_mean - y_lower\n",
    "    error_upper = y_upper - y_mean\n",
    "    plt.errorbar(noise_levels, y_mean, yerr=[error_lower, error_upper], linewidth=2, label=mesh_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
