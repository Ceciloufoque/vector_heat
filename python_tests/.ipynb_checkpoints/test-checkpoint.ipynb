{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import potpourri3d as pp3d\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_vertices(source_file_path, tolerance=1e-5):\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    \n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces\n",
    "\n",
    "    # Step 1: Find unique vertices within the given tolerance\n",
    "    kdtree = KDTree(vertices)\n",
    "    unique_indices = {}\n",
    "    canonical_vertices = []\n",
    "    \n",
    "    for i, vertex in enumerate(vertices):\n",
    "        if i in unique_indices:\n",
    "            continue  # Skip if already mapped to a canonical vertex\n",
    "        \n",
    "        # Find all vertices within the tolerance distance\n",
    "        duplicate_indices = kdtree.query_ball_point(vertex, tolerance)\n",
    "        \n",
    "        # Use the first duplicate as the \"canonical\" vertex and map all duplicates to it\n",
    "        canonical_index = len(canonical_vertices)\n",
    "        canonical_vertices.append(vertex)\n",
    "        \n",
    "        for idx in duplicate_indices:\n",
    "            unique_indices[idx] = canonical_index\n",
    "\n",
    "    # Step 2: Update faces to use only unique vertices\n",
    "    new_faces = np.array([[unique_indices[vi] for vi in face] for face in faces])\n",
    "\n",
    "    # Step 3: Create the new unified mesh\n",
    "    unified_mesh = trimesh.Trimesh(vertices=np.array(canonical_vertices), faces=new_faces)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_fixed.obj'\n",
    "    unified_mesh.export(output_path)\n",
    "    print(f'Mesh unified and saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_edges(source_file_path):\n",
    "    edges = mesh.edges\n",
    "    faces = mesh.faces\n",
    "    sorted_edges = np.sort(edges, axis=1)\n",
    "\n",
    "    # Find unique edges\n",
    "    _, unique_indices = np.unique(sorted_edges, axis=0, return_index=True)\n",
    "    unique_edges = edges[unique_indices]\n",
    "\n",
    "    # Find the vertices used by unique edges\n",
    "    unique_vertices = np.unique(unique_edges)\n",
    "\n",
    "    # Remap vertices for the unique edges\n",
    "    vertex_map = {old_index: new_index for new_index, old_index in enumerate(unique_vertices)}\n",
    "    remapped_vertices = np.array([vertex_map[vertex] for vertex in unique_vertices])\n",
    "\n",
    "    # Recreate the mesh using the unique edges and remapped vertices\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices[remapped_vertices], faces=faces, process=False)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_edges_cleaned.obj'\n",
    "    new_mesh.export(output_path)\n",
    "    print(f'Mesh cleaned and saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_faces_by_indices(mesh, face_indices):\n",
    "    # Convert face_indices to a set for fast exclusion\n",
    "    face_indices_set = set(face_indices)\n",
    "\n",
    "    # Create a mask that selects all faces except those we want to remove\n",
    "    mask = [i not in face_indices_set for i in range(len(mesh.faces))]\n",
    "\n",
    "    # Filter the faces array\n",
    "    new_faces = mesh.faces[mask]\n",
    "\n",
    "    # Recreate the mesh with the remaining faces\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices, faces=new_faces, process=False)\n",
    "    \n",
    "    return new_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nmwsharp/robust-laplacians-py/issues/1\n",
    "def add_random_jitter(source_file_path, level=1e-5):\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    jittered_vertices = mesh.vertices + np.random.normal(0, level, size= mesh.vertices.shape)\n",
    "    unified_mesh = trimesh.Trimesh(vertices=jittered_vertices, faces= mesh.faces)\n",
    "    output_path = source_file_path[:-4] + '_jittered.obj'\n",
    "    unified_mesh.export(output_path)\n",
    "    print(f'Mesh jittered and saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh cleaned and saved to dragon_edges_cleaned.obj\n"
     ]
    }
   ],
   "source": [
    "#add_random_jitter('dragon.obj', level=1)\n",
    "#remove_duplicate_edges('dragon.obj')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fefe558a72e46a0ada551015c3093a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:54320/index.html?ui=P_0x2580d7764a0_2&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mesh = trimesh.load('xyzrgb_dragon.obj')\n",
    "mesh = trimesh.load('dragon.obj')\n",
    "#mesh_jittered = trimesh.load('dragon_jittered.obj')\n",
    "\n",
    "# Set up the PyVista plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "\n",
    "\n",
    "# Tests\n",
    "troublesome_vertices = [34687, 34704]\n",
    "\n",
    "involved_faces = []\n",
    "for i, (x, y, z) in enumerate(mesh.faces):\n",
    "    if 34687 in [x,y,z] or 34704 in [x,y,z]:\n",
    "        involved_faces.append(i)\n",
    "        #print(i)\n",
    "#print(mesh.vertices.shape)\n",
    "mesh = remove_faces_by_indices(mesh, involved_faces)\n",
    "mesh.remove_unreferenced_vertices()\n",
    "#print(mesh.vertices.shape)\n",
    "\n",
    "#print(np.array(troublesome_vertices))\n",
    "for vertex in troublesome_vertices:\n",
    "    plotter.add_points(mesh.vertices[vertex].reshape(1, 3), color=\"blue\", render_points_as_spheres=True, point_size=10)\n",
    "\n",
    "\n",
    "# Scalar heat method\n",
    "source_vertex = 0\n",
    "heat_solver = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances = heat_solver.compute_distance(source_vertex)\n",
    "normalized_distances = (distances - distances.min()) / (distances.max() - distances.min())\n",
    "faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "plotter.add_mesh(pv_mesh, scalars=normalized_distances, cmap='viridis', show_edges=True)\n",
    "plotter.add_points(mesh.vertices[source_vertex].reshape(1, 3), color=\"red\", render_points_as_spheres=True, point_size=10)\n",
    "\n",
    "\n",
    "# Vector heat method\n",
    "source_vertex = 0\n",
    "source_vector = (1, 0)\n",
    "vector_solver = pp3d.MeshVectorHeatSolver(mesh.vertices, mesh.faces)\n",
    "\n",
    "# Intrinsic vectors\n",
    "intrinsic = vector_solver.transport_tangent_vector(source_vertex, source_vector)\n",
    "basisX, basisY, basisN = vector_solver.get_tangent_frames()\n",
    "\n",
    "# Extrinsic vectors\n",
    "#ext = vector_solver.transport_tangent_vector(source_vertex, source_vector)\n",
    "ext3D = intrinsic[:,0,np.newaxis] * basisX +  intrinsic[:,1,np.newaxis] * basisY\n",
    "plotter.add_arrows(mesh.vertices, ext3D, mag=0.1)\n",
    "\n",
    "#mesh_jittered = remove_faces_by_indices(mesh_jittered, involved_faces)\n",
    "#mesh_jittered.remove_unreferenced_vertices()\n",
    "#vector_solver_2 = pp3d.MeshVectorHeatSolver(mesh_jittered.vertices, mesh_jittered.faces)\n",
    "#vectors_jittered = vector_solver_2.transport_tangent_vector(source_vertex, source_vector)\n",
    "\n",
    "#plotter.show(title=\"Geodesic Distance Visualization\")\n",
    "#plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.deep_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance: 1.5772949929849003\n"
     ]
    }
   ],
   "source": [
    "#print(vectors[:10])\n",
    "#print(vectors_jittered[:10])\n",
    "\n",
    "distance_average = np.sum(np.abs(vectors-vectors_jittered))/vectors.shape[0]\n",
    "print(f'Average distance: {distance_average}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f4a78672b14265baf86ae152680a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:62223/index.html?ui=P_0x1b2b3354940_16&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.show(title=\"Geodesic Distance Visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
