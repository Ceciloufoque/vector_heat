{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import potpourri3d as pp3d\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_vertices(source_file_path, tolerance=1e-5):\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    \n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces\n",
    "\n",
    "    # Step 1: Find unique vertices within the given tolerance\n",
    "    kdtree = KDTree(vertices)\n",
    "    unique_indices = {}\n",
    "    canonical_vertices = []\n",
    "    \n",
    "    for i, vertex in enumerate(vertices):\n",
    "        if i in unique_indices:\n",
    "            continue  # Skip if already mapped to a canonical vertex\n",
    "        \n",
    "        # Find all vertices within the tolerance distance\n",
    "        duplicate_indices = kdtree.query_ball_point(vertex, tolerance)\n",
    "        \n",
    "        # Use the first duplicate as the \"canonical\" vertex and map all duplicates to it\n",
    "        canonical_index = len(canonical_vertices)\n",
    "        canonical_vertices.append(vertex)\n",
    "        \n",
    "        for idx in duplicate_indices:\n",
    "            unique_indices[idx] = canonical_index\n",
    "\n",
    "    # Step 2: Update faces to use only unique vertices\n",
    "    new_faces = np.array([[unique_indices[vi] for vi in face] for face in faces])\n",
    "\n",
    "    # Step 3: Create the new unified mesh\n",
    "    unified_mesh = trimesh.Trimesh(vertices=np.array(canonical_vertices), faces=new_faces)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_fixed.obj'\n",
    "    unified_mesh.export(output_path)\n",
    "    print(f'Mesh unified and saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_edges(source_file_path):\n",
    "    #######add-in########\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    ################################\n",
    "    edges = mesh.edges\n",
    "    faces = mesh.faces\n",
    "    sorted_edges = np.sort(edges, axis=1)\n",
    "\n",
    "    # Find unique edges\n",
    "    _, unique_indices = np.unique(sorted_edges, axis=0, return_index=True)\n",
    "    unique_edges = edges[unique_indices]\n",
    "\n",
    "    # Find the vertices used by unique edges\n",
    "    unique_vertices = np.unique(unique_edges)\n",
    "\n",
    "    # Remap vertices for the unique edges\n",
    "    vertex_map = {old_index: new_index for new_index, old_index in enumerate(unique_vertices)}\n",
    "    remapped_vertices = np.array([vertex_map[vertex] for vertex in unique_vertices])\n",
    "\n",
    "\n",
    "    # Recreate the mesh using the unique edges and remapped vertices\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices[remapped_vertices], faces=faces, process=False)\n",
    "\n",
    "    output_path = source_file_path[:-4] + '_edges_cleaned.obj'\n",
    "    new_mesh.export(output_path)\n",
    "    print(f'Mesh cleaned and saved to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_faces_by_indices(mesh, face_indices):\n",
    "    # Convert face_indices to a set for fast exclusion\n",
    "    face_indices_set = set(face_indices)\n",
    "\n",
    "    # Create a mask that selects all faces except those we want to remove\n",
    "    mask = [i not in face_indices_set for i in range(len(mesh.faces))]\n",
    "\n",
    "    # Filter the faces array\n",
    "    new_faces = mesh.faces[mask]\n",
    "\n",
    "    # Recreate the mesh with the remaining faces\n",
    "    new_mesh = trimesh.Trimesh(vertices=mesh.vertices, faces=new_faces, process=False)\n",
    "    \n",
    "    return new_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nmwsharp/robust-laplacians-py/issues/1\n",
    "def add_random_jitter(source_file_path, level=1e-5):\n",
    "    mesh = trimesh.load(source_file_path)\n",
    "    jittered_vertices = mesh.vertices + np.random.normal(0, level, size= mesh.vertices.shape)\n",
    "    unified_mesh = trimesh.Trimesh(vertices=jittered_vertices, faces= mesh.faces)\n",
    "    output_path = source_file_path[:-4] + '_jittered.obj'\n",
    "    unified_mesh.export(output_path)\n",
    "    print(f'Mesh jittered and saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4749582ec4f549beae32f1a77e328561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:64487/index.html?ui=P_0x231ffd349a0_26&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import trimesh\n",
    "import potpourri3d as pp3d\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "\n",
    "# Load the mesh\n",
    "mesh = trimesh.load('spot_fixed_edges_cleaned.obj')\n",
    "\n",
    "# Set up the PyVista plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Multisource: source 1 + source 2\n",
    "multisource_vertex= [0, 100]\n",
    "heat_solver_1 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_multisource = heat_solver_1.compute_distance_multisource(multisource_vertex)\n",
    "\n",
    "# First Source\n",
    "source_vertex_1 = multisource_vertex[0]\n",
    "heat_solver_1 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_1 = heat_solver_1.compute_distance(source_vertex_1)\n",
    "\n",
    "# Second Source\n",
    "source_vertex_2 = multisource_vertex[1]\n",
    "heat_solver_2 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_2 = heat_solver_2.compute_distance(source_vertex_2)\n",
    "\n",
    "# # Normalize distances for visualization\n",
    "# normalized_distances_1 = (distances_1 - distances_1.min()) / (distances_1.max() - distances_1.min())\n",
    "# normalized_distances_2 = (distances_2 - distances_2.min()) / (distances_2.max() - distances_2.min())\n",
    "\n",
    "# Combine Distance Information for Visualization\n",
    "normalized_distances_multisource = (distances_multisource - distances_multisource.min()) / (distances_multisource.max() - distances_multisource.min())\n",
    "\n",
    "# # Prepare the mesh for PyVista\n",
    "# faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "# pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "\n",
    "# Add the combined geodesic distance visualization\n",
    "plotter.add_mesh(pv_mesh, scalars=normalized_distances_multisource, cmap='viridis', show_edges=True)\n",
    "\n",
    "# Prepare the mesh for PyVista\n",
    "faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "\n",
    "# Find Cut Locus Points (where distances are approximately equal)\n",
    "tolerance = 0.05  # Adjust for precision\n",
    "cut_locus_vertices = np.where(np.abs(distances_1 - distances_2) < tolerance)[0]\n",
    "\n",
    "plotter.add_points(mesh.vertices[source_vertex_1].reshape(1, 3), color=\"red\", render_points_as_spheres=True, point_size=10, label=\"Source 1\")\n",
    "plotter.add_points(mesh.vertices[source_vertex_2].reshape(1, 3), color=\"red\", render_points_as_spheres=True, point_size=10, label=\"Source 2\")\n",
    "\n",
    "# Highlight the cut locus points\n",
    "plotter.add_points(mesh.vertices[cut_locus_vertices], color=\"blue\", render_points_as_spheres=True, point_size=8, label=\"Cut Locus\")\n",
    "\n",
    "# Vector Heat Method for multisource\n",
    "vector_solver_multisource = pp3d.MeshVectorHeatSolver(mesh.vertices, mesh.faces)\n",
    "multisource_vector = [(1, 0), (0, 1)]\n",
    "\n",
    "# Transport tangent vector for multisource\n",
    "intrinsic_multisource = vector_solver_multisource.transport_tangent_vectors(multisource_vertex, multisource_vector)\n",
    "basisX_multisource, basisY_multisource, _ = vector_solver_multisource.get_tangent_frames()\n",
    "ext3D_multisource = intrinsic_multisource[:, 0, np.newaxis] * basisX_multisource + intrinsic_multisource[:, 1, np.newaxis] * basisY_multisource\n",
    "\n",
    "# Add vector transport visualization for multisource\n",
    "plotter.add_arrows(mesh.vertices, ext3D_multisource, mag=0.1, color=\"yellow\", label=\"Vectors from Source 1 and Source 2\")\n",
    "\n",
    "# Add legend and show the plot\n",
    "plotter.add_legend()\n",
    "plotter.show(title=\"Cut Locus Visualization with Vector Heat Method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9860fe9e96419c95110c74a9f63af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:64487/index.html?ui=P_0x231ff5a76a0_28&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import trimesh\n",
    "import potpourri3d as pp3d\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "\n",
    "# Load the mesh\n",
    "mesh = trimesh.load('spot_fixed_edges_cleaned.obj')\n",
    "\n",
    "# Set up the PyVista plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Multisource: source 1 + source 2\n",
    "multisource_vertex= [0, 100]\n",
    "heat_solver_1 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_multisource = heat_solver_1.compute_distance_multisource(multisource_vertex)\n",
    "\n",
    "# First Source\n",
    "source_vertex_1 = multisource_vertex[0]\n",
    "heat_solver_1 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_1 = heat_solver_1.compute_distance(source_vertex_1)\n",
    "\n",
    "# Second Source\n",
    "source_vertex_2 = multisource_vertex[1]\n",
    "heat_solver_2 = pp3d.MeshHeatMethodDistanceSolver(mesh.vertices, mesh.faces)\n",
    "distances_2 = heat_solver_2.compute_distance(source_vertex_2)\n",
    "\n",
    "# # Normalize distances for visualization\n",
    "# normalized_distances_1 = (distances_1 - distances_1.min()) / (distances_1.max() - distances_1.min())\n",
    "# normalized_distances_2 = (distances_2 - distances_2.min()) / (distances_2.max() - distances_2.min())\n",
    "\n",
    "# Combine Distance Information for Visualization\n",
    "normalized_distances_multisource = (distances_multisource - distances_multisource.min()) / (distances_multisource.max() - distances_multisource.min())\n",
    "\n",
    "# # Prepare the mesh for PyVista\n",
    "# faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "# pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "\n",
    "# Add the combined geodesic distance visualization\n",
    "plotter.add_mesh(pv_mesh, scalars=normalized_distances_multisource, cmap='viridis', show_edges=True)\n",
    "\n",
    "# Prepare the mesh for PyVista\n",
    "faces_with_sizes = np.hstack([np.full((mesh.faces.shape[0], 1), 3), mesh.faces]).flatten()\n",
    "pv_mesh = pv.PolyData(mesh.vertices, faces_with_sizes)\n",
    "\n",
    "# Find Cut Locus Points (where distances are approximately equal)\n",
    "tolerance = 0.05  # Adjust for precision\n",
    "cut_locus_vertices = np.where(np.abs(distances_1 - distances_2) < tolerance)[0]\n",
    "\n",
    "plotter.add_points(mesh.vertices[source_vertex_1].reshape(1, 3), color=\"red\", render_points_as_spheres=True, point_size=10, label=\"Source 1\")\n",
    "plotter.add_points(mesh.vertices[source_vertex_2].reshape(1, 3), color=\"red\", render_points_as_spheres=True, point_size=10, label=\"Source 2\")\n",
    "\n",
    "# Highlight the cut locus points\n",
    "plotter.add_points(mesh.vertices[cut_locus_vertices], color=\"blue\", render_points_as_spheres=True, point_size=8, label=\"Cut Locus\")\n",
    "\n",
    "# Vector Heat Method for multisource\n",
    "vector_solver_multisource = pp3d.MeshVectorHeatSolver(mesh.vertices, mesh.faces)\n",
    "multisource_vector = [(1, 0), (0, 1)]\n",
    "\n",
    "# # Transport tangent vector for multisource\n",
    "# intrinsic_multisource = vector_solver_multisource.transport_tangent_vectors(multisource_vertex, multisource_vector)\n",
    "# basisX_multisource, basisY_multisource, _ = vector_solver_multisource.get_tangent_frames()\n",
    "# ext3D_multisource = intrinsic_multisource[:, 0, np.newaxis] * basisX_multisource + intrinsic_multisource[:, 1, np.newaxis] * basisY_multisource\n",
    "\n",
    "# # Add vector transport visualization for multisource\n",
    "# plotter.add_arrows(mesh.vertices, ext3D_multisource, mag=0.1, color=\"yellow\", label=\"Vectors from Source 1 and Source 2\")\n",
    "\n",
    "# Add legend and show the plot\n",
    "plotter.add_legend()\n",
    "plotter.show(title=\"Cut Locus Visualization with Vector Heat Method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_vector_heat_demo",
   "language": "python",
   "name": "vector_heat_demo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
